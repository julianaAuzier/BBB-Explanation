{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea1703c7",
   "metadata": {},
   "source": [
    "## Peptídeos de Penetração Hematoencefálica"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e90885",
   "metadata": {},
   "source": [
    "### Bibliotecas comumente utilizadas ao longo do código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e25ab1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib as jl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pathlib as pl\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07bdcf1d",
   "metadata": {},
   "source": [
    "### Funções para carregar a base de dados e retornar os dados em Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a483776",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load\n",
    "\n",
    "def data_frame_from_excel(*args, **kwargs) -> pd.DataFrame:\n",
    "    return pd.read_excel(*args, **kwargs)\n",
    "\n",
    "\n",
    "def data_frame_from_csv(*args, **kwargs) -> pd.DataFrame:\n",
    "    return pd.read_csv(*args, **kwargs)\n",
    "\n",
    "\n",
    "def array_as_memory_map(array: np.ndarray, *, directory: pl.Path) -> np.memmap:\n",
    "    if not directory.is_dir():\n",
    "        directory.mkdir()\n",
    "\n",
    "    memory_map_path = pl.Path(directory) / \"memory_map\"\n",
    "\n",
    "    jl.dump(array, memory_map_path)\n",
    "\n",
    "    return jl.load(memory_map_path, mmap_mode=\"r\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767f5b72",
   "metadata": {},
   "source": [
    "### Criação de um mapa de memória, onde os arquivos mapeados na memória são usados para acessar pequenos segmentos de arquivos grandes no disco, sem ler o arquivo inteiro na memória. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90bc95d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def array_as_memory_map(array: np.ndarray, *, directory: pl.Path) -> np.memmap:\n",
    "    if not directory.is_dir():\n",
    "        directory.mkdir()\n",
    "\n",
    "    memory_map_path = pl.Path(directory) / \"memory_map\"\n",
    "\n",
    "    jl.dump(array, memory_map_path)\n",
    "\n",
    "    return jl.load(memory_map_path, mmap_mode=\"r\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d68601c",
   "metadata": {},
   "source": [
    "### Silhouette scores\n",
    "O valor do coeficiente de silhueta é um valor de -1 a 1, onde um valor alto indica que o objeto está bem combinado com seu próprio cluster e mal combinado com os clusters vizinhos. Se a maioria dos objetos tiver um valor alto, a configuração de cluster é apropriada. Se muitos pontos tiverem um valor baixo ou negativo, a configuração de cluster pode ter muitos ou poucos clusters, ou seja, uma configuração de clusters diferente do apresentado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad584fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#score\n",
    "\n",
    "from sklearn import cluster, metrics\n",
    "\n",
    "\n",
    "def get_silhouette_scores(data_frame: pd.DataFrame, *, parallel: jl.Parallel = None) -> pd.DataFrame:\n",
    "    columns = [data_frame.loc[:, [column]] for column in data_frame.columns]\n",
    "\n",
    "    if parallel is not None:\n",
    "        scores = parallel(jl.delayed(__get_silhouette_score__)(column) for column in columns)\n",
    "    else:\n",
    "        scores = [__get_silhouette_score__(column) for column in columns]\n",
    "\n",
    "    index = pd.Index(data_frame.columns.values, name=\"Feature\")\n",
    "    columns = pd.Index((\"Silhouette score\",), name=\"Measure\")\n",
    "\n",
    "    return pd.DataFrame(scores, index=index, columns=columns)\n",
    "\n",
    "\n",
    "def evaluate_k_means_silhouette(individual: np.ndarray, *, descriptors: np.memmap, final_dim: int) -> tuple[float]:\n",
    "    if individual.sum() != final_dim:\n",
    "        return -1.,\n",
    "\n",
    "    selected_descriptors = descriptors[:, individual]\n",
    "\n",
    "    return __get_silhouette_score__(selected_descriptors),\n",
    "\n",
    "\n",
    "# noinspection PyUnresolvedReferences\n",
    "def __get_silhouette_score__(data_frame: pd.DataFrame) -> float:\n",
    "    return metrics.silhouette_score(data_frame, cluster.KMeans(n_clusters=2).fit(data_frame).labels_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fabc456",
   "metadata": {},
   "source": [
    "### Pré-processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61358697",
   "metadata": {},
   "outputs": [],
   "source": [
    "import typing as t\n",
    "from feature_engine import selection\n",
    "\n",
    "# Apaga atributos iguais\n",
    "def drop_constant_features(data_frame: pd.DataFrame, *, tolerance: float) -> pd.DataFrame:\n",
    "    return selection.DropConstantFeatures(tol=tolerance).fit_transform(data_frame)\n",
    "\n",
    "# Apaga atributos correlacionados\n",
    "def drop_correlated_features(\n",
    "        data_frame: pd.DataFrame, sorted_scores: pd.DataFrame, *, tolerance: float) -> pd.DataFrame:\n",
    "    flagged_feature_names = __get_correlated_feature_names__(data_frame, tolerance=tolerance)\n",
    "\n",
    "    print(f\"Correlated features found: {len(flagged_feature_names)}.\")\n",
    "\n",
    "    while len(flagged_feature_names) > 0:\n",
    "        print(f\"Remaining correlated features: {len(flagged_feature_names)}.\", end=\"\\r\")\n",
    "\n",
    "        worst_performing_column_name = sorted_scores.loc[flagged_feature_names, :].index.values[0]\n",
    "        data_frame = data_frame.drop(worst_performing_column_name, axis=1)\n",
    "        flagged_feature_names = __get_correlated_feature_names__(data_frame, tolerance=tolerance)\n",
    "\n",
    "    print(\"All correlated features removed.\")\n",
    "\n",
    "    return data_frame\n",
    "\n",
    "# Obtém os nomes dos atributos correlacionados\n",
    "def __get_correlated_feature_names__(data_frame: pd.DataFrame, *, tolerance: float) -> tuple[t.Any, ...]:\n",
    "    correlation_matrix = data_frame.corr(method=\"spearman\").abs()\n",
    "    upper_triangle = correlation_matrix.where(np.triu(np.ones(correlation_matrix.shape), k=1).astype(np.bool_))\n",
    "\n",
    "    return tuple(column for column in upper_triangle.columns if any(upper_triangle[column] > tolerance))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83668b7b",
   "metadata": {},
   "source": [
    "### Otimização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c9cf4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deap import algorithms, base, creator, tools\n",
    "\n",
    "def get_toolbox(\n",
    "        *, descriptors: np.memmap, final_dim: int, ind_size: int, pop_size: int, parallel: jl.Parallel = None\n",
    ") -> base.Toolbox:\n",
    "    creator.create(\"Score\", base.Fitness, weights=(1.0,))\n",
    "    # noinspection PyUnresolvedReferences\n",
    "    creator.create(\"Individual\", np.ndarray, dtype=\"bool\", fitness=creator.Score)\n",
    "\n",
    "    toolbox = base.Toolbox()\n",
    "\n",
    "    # if parallel is not None:\n",
    "    #     toolbox.register(\"map\", joblib_map, parallel=parallel)\n",
    "\n",
    "    # noinspection PyUnresolvedReferences\n",
    "    toolbox.register(\"individual\", create_individual, size=ind_size, final_dim=final_dim)\n",
    "    # noinspection PyUnresolvedReferences\n",
    "    toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual, n=pop_size)\n",
    "\n",
    "    toolbox.register(\"evaluate\", evaluate_k_means_silhouette, descriptors=descriptors, final_dim=final_dim)\n",
    "    toolbox.register(\"mate\", tools.cxPartialyMatched)\n",
    "    toolbox.register(\"mutate\", tools.mutFlipBit, indpb=0.1)\n",
    "    toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "\n",
    "    return toolbox\n",
    "\n",
    "\n",
    "# noinspection PyUnresolvedReferences\n",
    "def create_individual(size: int, *, final_dim: int):\n",
    "    array = np.zeros(size, dtype=np.bool_)\n",
    "    random_indices = np.random.randint(0, size, size=final_dim)\n",
    "    array[random_indices] = np.True_\n",
    "\n",
    "    # noinspection PyUnresolvedReferences\n",
    "    return creator.Individual(array)\n",
    "\n",
    "\n",
    "def joblib_map(function: t.Callable, *arg_lists, parallel: jl.Parallel):\n",
    "    return parallel(jl.delayed(function)(*args) for args in zip(*arg_lists))\n",
    "\n",
    "\n",
    "def genetic_algorithm(toolbox: base.Toolbox) -> list[np.ndarray]:\n",
    "    # noinspection PyUnresolvedReferences\n",
    "    population = toolbox.population()\n",
    "    best_dim, best_fit = 0, 0\n",
    "\n",
    "    gen, gens_without_progress = 0, 0\n",
    "\n",
    "    while gens_without_progress < 100:\n",
    "        gen += 1\n",
    "        print_prefix = f\"[{gen} ({gens_without_progress} without progress) | \" \\\n",
    "                       f\"Best individual: (D = {best_dim}, F = {best_fit})]\"\n",
    "\n",
    "        print(f\"{print_prefix} Selecting parents...\", end=\"\\r\")\n",
    "        # noinspection PyUnresolvedReferences\n",
    "        offspring = toolbox.select(population, k=len(population) // 2) + toolbox.population(n=len(population) // 2)\n",
    "        print(f\"{print_prefix} Mating and mutating selected parents...\", end=\"\\r\")\n",
    "        offspring = algorithms.varAnd(offspring, toolbox, cxpb=0.5, mutpb=0.2)\n",
    "        print(f\"{print_prefix} Scoring offspring fitness...\", end=\"\\r\")\n",
    "        # noinspection PyUnresolvedReferences\n",
    "        values = toolbox.map(toolbox.evaluate, offspring)\n",
    "\n",
    "        for value, individual in zip(values, offspring):\n",
    "            individual.fitness.values = value\n",
    "\n",
    "        print(f\"{print_prefix} Selecting best from parents and children...\", end=\"\\r\")\n",
    "        # noinspection PyUnresolvedReferences\n",
    "        population = toolbox.select(population + offspring, k=len(population))\n",
    "\n",
    "        best_ind = tools.selBest(population, k=1)\n",
    "        dim, fit = np.where(best_ind[0] == 1)[0].size, best_ind[0].fitness.values[0]\n",
    "\n",
    "        if dim == best_dim and fit == best_fit:\n",
    "            gens_without_progress += 1\n",
    "        else:\n",
    "            best_dim, best_fit = dim, fit\n",
    "            gens_without_progress = 0\n",
    "\n",
    "    print(f\"{print_prefix} Execution finished.\")\n",
    "\n",
    "    return tools.selBest(population, k=1)[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f344c92c",
   "metadata": {},
   "source": [
    "### Execução"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76697337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[132 (99 without progress) | Best individual: (D = 5, F = 0.9877497906071292)] Execution finished. parents and children...\n"
     ]
    }
   ],
   "source": [
    "#playground\n",
    "import pathlib as pl\n",
    "\n",
    "import joblib as jl\n",
    "\n",
    "#from pipeline import load, preprocess, score, optimize\n",
    "\n",
    "#for i in range(50):\n",
    "descriptors_file = pl.Path(\"data/descriptors.xlsx\")\n",
    "output_directory = pl.Path(\"results\")#+str(i))\n",
    "\n",
    "if not output_directory.is_dir():\n",
    "    output_directory.mkdir()\n",
    "\n",
    "variance_threshold, correlation_threshold = .95, .7\n",
    "n_jobs = -1\n",
    "final_dimensionality = 5\n",
    "population_size = 100\n",
    "\n",
    "\n",
    "with jl.Parallel(n_jobs=n_jobs) as parallel:\n",
    "    if not (output_directory / \"final_descriptors.csv\").is_file():\n",
    "        descriptors = data_frame_from_excel(\n",
    "            descriptors_file, sheet_name=\"Blad1\", header=2, index_col=0\n",
    "        ).reset_index(drop=True)\n",
    "        filtered_descriptors = drop_constant_features(descriptors, tolerance=variance_threshold)\n",
    "        scores = get_silhouette_scores(filtered_descriptors, parallel=parallel)\n",
    "        final_descriptors = drop_correlated_features(\n",
    "            filtered_descriptors, scores.sort_values(by=\"Silhouette score\"), tolerance=correlation_threshold)\n",
    "        final_descriptors.to_csv(output_directory / \"final_descriptors.csv\", sep=\";\", index=False)\n",
    "    else:\n",
    "        final_descriptors = data_frame_from_csv(output_directory / \"final_descriptors.csv\", sep=\";\")\n",
    "\n",
    "    data_memory_map = array_as_memory_map(final_descriptors.to_numpy(), directory=output_directory)\n",
    "\n",
    "    toolbox = get_toolbox(\n",
    "        descriptors=data_memory_map,\n",
    "        final_dim=final_dimensionality,\n",
    "        ind_size=final_descriptors.shape[1],\n",
    "        pop_size=population_size,\n",
    "        parallel=parallel\n",
    "    )\n",
    "\n",
    "    best_solution = genetic_algorithm(toolbox)\n",
    "    final_descriptors.iloc[:, best_solution].to_csv(output_directory / \"selected_descriptors.csv\", sep=\";\", index=False)\n",
    "\n",
    "    with open(output_directory / \"selected_descriptors_fitness.txt\", \"w\", encoding=\"utf-8\") as file:\n",
    "        # noinspection PyUnresolvedReferences\n",
    "        file.write(str(best_solution.fitness.values[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b7e443",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05d58cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
